EMPOWERING THE VISUALLY IMPAIRED WITH REAL TIME OBJECT RECOGNITION WITH AUDIO ASSISTANCE

                               ABSTRACT

The proposed project, "Empowering the Visually Impaired with

Real-Time Object Recognition with Audio Assistance," is designed to

address the critical mobility challenges faced by visually impaired

individuals. Traditional navigation aids like white canes and guide dogs 

offer limited assistance, often leaving users vulnerable to obstacles that are

beyond immediate tactile range or awareness. This project leverages

advanced technology to enhance real-time navigation and ensure a safer,

more independent experience for users.

At the core of this project is the ESP32-CAM module, a low-cost,

Wi-Fi-enabled microcontroller that is integrated with a camera to provide

real-time object recognition. The camera captures the user’s environment

and employs the YOLO Tiny-4 object detection model to identify obstacles

in the path of the user. The use of YOLO, a fast and efficient deep learning

model, ensures that object detection occurs in real-time with high accuracy,

allowing the user to avoid hazards in dynamic environments.

Simultaneously, ultrasonic sensors are utilized to measure the distance

between the user and detected objects, providing depth perception and

enhancing safety. This dual approach—object recognition combined with

distance measurement—offers a comprehensive understanding of the user's

surroundings, far surpassing the capabilities of traditional navigation aids.

Once the objects and obstacles are detected, the system generates

clear, spoken instructions using a Text-to-Speech (TTS) engine. These

instructions guide the user around obstacles, delivering precise, easy-to-

understand voice commands such as “Move left” or “Object ahead.” The

real-time audio feedback is critical in ensuring that the user can make quick,

informed decisions about their movements. The system operates offline,meaning that it does not rely on external networks or cloud services, making

it suitable for use in any environment, regardless of internet availability.

The project focuses heavily on portability and usability, with the

entire system housed within a lightweight, wearable glasses frame. This form

factor ensures that users can easily integrate the device into their daily

routines without experiencing discomfort or requiring additional equipment.

The use of cost-effective components such as the ESP32-CAM and

ultrasonic sensors ensures that the solution remains affordable and accessible

to a wide range of users, particularly in areas where expensive assistive

technology may not be feasible.

In addition to the core functionality of object detection and audio

assistance, the project has the potential for future expansion. Features such

as GPS integration, more sophisticated object classification, and

customization of voice commands could further enhance the user experience,

making the system even more adaptive to individual needs. The goal of the

project is not only to improve navigation for visually impaired individuals

but also to empower them with greater independence, confidence, and safety

in their daily lives.

Overall, this project represents a significant advancement in assistive

technology for visually impaired individuals. By combining cutting-edge

object recognition, real-time feedback, and an accessible design,

"Empowering the Visually Impaired with Real-Time Object Recognition

with Audio Assistance" aims to transform the way visually impaired 

individuals interact with their surroundings, fostering greater autonomy and 

inclusion ina world where mobility is essential for independence.
